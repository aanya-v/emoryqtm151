{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> Lecture 16 - Practicing Chaining </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "In this lecture you will get a chance to practice <br>\n",
    "the main dataset operations\n",
    "\n",
    "- There will be a quiz on this lecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> I. Import Libraries and Data </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = pd.read_csv(\"data_raw/results.csv\")\n",
    "races    = pd.read_csv(\"data_raw/races.csv\")\n",
    "results[\"points col\"] = results[\"points\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> II. Review Dataset Operations </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "See attached file for a refresher on syntax\n",
    "\n",
    "```[] ``` $\\qquad \\qquad \\qquad \\quad$: Extracting columns <br>\n",
    "```.query() ``` $\\qquad \\qquad $: Subsetting rows <br>\n",
    "```.recode() ``` $ \\qquad \\quad \\ \\ $: Replacing values <br>\n",
    "```.groupby().agg() ```: Aggregate statistics by subgroup <br>\n",
    "```.rename() ``` $\\qquad \\quad \\ \\ $: Change name of columns\n",
    "\n",
    "Full list:\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "https://www.w3schools.com/python/pandas/pandas_ref_dataframe.asp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> III. Examples of Chaining </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "The operations with \".\" are read left to right\n",
    "\n",
    "- Combine any of the above operations\n",
    "- Great way to make code efficient\n",
    "- The sky's the limit!\n",
    "\n",
    "\n",
    "Subsetting **before** extracting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for drivers that scored more than 20 points on individual races\n",
    "# Then extract the columns \"driverId\" and \"points\"\n",
    "results.query('points >= 20')[[\"driverId\",\"points\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Subsetting **before** aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This obtains a subset of drivers who competed in races 500 onwards\n",
    "# then computes the average by team (\"constructorId\")\n",
    "\n",
    "(results.query('raceId >= 500')\n",
    "        .groupby(\"constructorId\")\n",
    "        .agg(mean_points = (\"points\",\"mean\")))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Subsetting **after** aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This obtains the average points by team (\"constructorId\"), then \n",
    "# produces a subset of team whose average is higher than 10\n",
    "\n",
    "(results.groupby(\"constructorId\")\n",
    "        .agg(mean_points = (\"points\",\"mean\"))\n",
    "        .query('mean_points >= 10'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Chaining inside queries + NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"is.na()\" produces a True/False vector, checking for missing values\n",
    "# \"is.notna()\" produces a True/False vector, checking for non-missing values\n",
    "# .str.isnumeric()\n",
    "results[\"points\"].isna()\n",
    "results[\"points\"].notna()\n",
    "\n",
    "subset_nas    = results.query('points.isna()')\n",
    "subset_nonnas = results.query('points.notna()')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue\"> III. Quiz Structure </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "The day of the quiz I will ...\n",
    "- Provide a dataset with information\n",
    "- Give more specific instructions.\n",
    "- Below, you will see the type of questions that will be asked.\n",
    "- The idea is for you to apply known concepts to new data\n",
    "- You have 50 minutes to complete the assignment\n",
    "\n",
    "Questions\n",
    "\n",
    "(exact wording may change in quiz, but exercise will be very similar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "(a) Replace the values of a column\n",
    "\n",
    "- Obtain unique string values of a column\n",
    "- Use the \".replace()\" command\n",
    "\n",
    "Hint: See Lecture 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"data_raw/results.csv\")\n",
    "\n",
    "subset      = results.query(\"milliseconds.str.isnumeric() == False\")\n",
    "list_unique = pd.unique(subset[\"milliseconds\"])\n",
    "print(list_unique)\n",
    "list_old = ['\\\\N']\n",
    "list_new = [np.nan]\n",
    "results[\"milliseconds\"] = results[\"milliseconds\"].replace(list_old, list_new) #replaces vals\n",
    "results[\"milliseconds_numeric\"] = pd.to_numeric(results[\"milliseconds\"]) # converts col to numeric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(b) Recode a numeric column\n",
    "\n",
    "- Use the \"pd.cut()\" command to create <br>\n",
    "a new column based on an interval.\n",
    "- See Lecture 13 for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits = pd.read_csv(\"data_raw/circuits.csv\")\n",
    "\n",
    "bins_x = [0,2500, 5000]\n",
    "labels_x = [\"Between 0 and 2500\",\n",
    "            \"Between 2500 and 5000\"]\n",
    "\n",
    "#tells u what's old and new\n",
    "subset      = circuits.query(\"alt.str.isnumeric() == False\")\n",
    "list_unique = pd.unique(subset[\"alt\"])\n",
    "print(list_unique)\n",
    "\n",
    "#replacing\n",
    "list_oldy = ['\\\\N','-7']\n",
    "list_newy = [np.nan,-7]\n",
    "circuits[\"alt\"] = circuits[\"alt\"].replace(list_oldy, list_newy)\n",
    "circuits[\"alt_numeric\"] = pd.to_numeric(circuits[\"alt\"])\n",
    "\n",
    "#change to numeric\n",
    "\n",
    "\n",
    "results[\"bins_alt\"] = pd.cut(circuits[\"alt_numeric\"],\n",
    "                              bins = bins_x,\n",
    "                              right = True,\n",
    "                              labels = labels_x)\n",
    "\n",
    "#       float(\"inf\") and float(\"-inf\") represent infinity and negative infinity\n",
    "#       The \"right\" command indicates that the right interval is\n",
    "#       \"less than or equal to\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(c) Aggregate and query\n",
    "\n",
    "- Use a combniation of the following commands <br>\n",
    "to produce a new dataset <br>\n",
    "``` .query() ``` <br>\n",
    "``` .groupby().agg() ``` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_agg_2 = (results.query(\"raceId >= 200\")\n",
    "                       .groupby(\"constructorId\")\n",
    "                        .agg(mean_laps = ('laps','mean'),\n",
    "                           sd_laps =   ('laps','std')))\n",
    "\n",
    "results_agg_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(d) Aggregate and sort\n",
    "\n",
    "- Use a combniation of the following commands <br>\n",
    "to produce a new dataset <br>\n",
    "``` .groupby().agg() ``` <br>\n",
    "``` .sort_values() ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_agg = (results.groupby(\"constructorId\")\n",
    "                      .agg(mean_laps = ('laps','mean'),\n",
    "                           sd_laps =   ('laps','std'))\n",
    "                           .sort_values (by = \"mean_laps\", ascending = False))\n",
    "\n",
    "results_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(e) Rename column\n",
    "\n",
    "- Create a dictionary\n",
    "- Rename one or more columns in a dataset <br>\n",
    "using the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "car_dictionary = {\"car_model\": [\"Ferrari\",\"Tesla\",\"BMW\"],\n",
    "                  \"year\":      [\"2018\",\"2023\",\"2022\"] }\n",
    "\n",
    "\n",
    "races_raw    = pd.read_csv(\"data_raw/races.csv\")\n",
    "\n",
    "#renaming one col\n",
    "dict_rename_circuits = {\"name\": \"circuit_name\"}\n",
    "circuits = circuits.rename(columns = dict_rename_circuits)\n",
    "print (races.columns.values)\n",
    "\n",
    "#renaming multiple\n",
    "#dict_rename_pitfall = {\"name_x\": \"race_name\",\n",
    "#                       \"name_y\" : \"circuit_name\"} #sep with comma\n",
    "#races_merge_pitfalls = races_raw.rename(columns = dict_rename_pitfall)\n",
    "\n",
    "#print (races_merge_pitfalls.columns.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(f) Merge dataset\n",
    "\n",
    "- Use \"pd.merge\" to combine two datasets: <br>\n",
    "a primary and secondary\n",
    "- Only merge a subset of the columns of the <br>\n",
    "secondary dataset\n",
    "- Use \"display\" to show a the merged dataset,  <br>\n",
    "extracting a subset of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "races_merge = pd.merge(races_raw,\n",
    "                       circuits[[\"circuitId\",\"circuit_name\"]], # multiple\n",
    "                       on = \"circuitId\",\n",
    "                       how = \"left\")\n",
    "\n",
    "display (races_merge[[\"raceId\", \"circuitId\", \"circuit_name\"]].sort_values(by = \"circuitId\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45fc1f684f6f416f40889115beff3ddf69879b64cf4bfee48cb72a61e9d15d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
